{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/ryass.DESKTOP-0A1NS33/OneDrive/practice_python/scrap_data/amazon/amazon.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "df_coffee_reviews = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_coffee_reviews['product_encode']=pd.get_dummies(df_coffee_reviews['product']).values.argmax(1)\n",
    "print(df_coffee_reviews['product_encode'].value_counts())\n",
    "print(df_coffee_reviews['product'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(df_coffee_reviews.shape)\n",
    "print(df_coffee_reviews.columns)\n",
    "df_coffee_reviews.info()\n",
    "print(df_coffee_reviews.describe(include='object'))\n",
    "df_coffee_reviews['stars'] = df_coffee_reviews.stars.astype('float64')\n",
    "df_coffee_reviews['date'] = pd.to_datetime(df_coffee_reviews['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coffee_reviews.groupby(by='product')['name'].count().plot.bar()\n",
    "#sns.boxplot(data=df_coffee_reviews, y='stars', x='date',hue='product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coffee_reviews.groupby(by=['product',df_coffee_reviews['date'].dt.year]).aggregate({'stars':'mean'}).unstack().T.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coffee_reviews.groupby(by=['product',df_coffee_reviews['date'].dt.year]).count()['name'].unstack().T.plot.bar(xlabel='Date',ylabel='Counts') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coffee_reviews.groupby(by=['date','stars'])['name'].count().to_frame(name='counts').plot(xlabel='Date,Stars',ylabel='Counts')\n",
    "\n",
    "plt.xticks(rotation='45');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans, DBSCAN,AgglomerativeClustering\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.stem import WordNetLemmatizer,SnowballStemmer\n",
    "nltk.download('wordnet')\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review_train=df_coffee_reviews['review'].str.lower().str.translate(str.maketrans('', '', string.punctuation)).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "porter_stemmer=PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "snowball_stemmer=SnowballStemmer(\"english\",ignore_stopwords=True)\n",
    "\n",
    "def my_text_preprocessor(text):\n",
    "    \n",
    "    text=text.lower() \n",
    "    text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
    "    text=re.sub(\"[^A-Za-z]+\",\" \", text)\n",
    "    text=re.sub(\"\\\\s+(in|the|all|for|and|on|you|we|your)\\\\s+\",\" \",text) \n",
    "    \n",
    "    # stem words\n",
    "    words=re.split(\"\\\\s+\",text)\n",
    "    stemmed_words=[porter_stemmer.stem(word=word) for word in words if word.isalpha()]\n",
    "    #snowball\n",
    "    snowballstemmer_words=[snowball_stemmer.stem(word) for word in words if word.isalpha()] \n",
    "    #lematize words\n",
    "    lemmat_words=[lemmatizer.lemmatize(word=word) for word in words if word.isalpha()]\n",
    "    \n",
    "    #return ' '.join(stemmed_words)\n",
    "    return ' '.join(lemmat_words)\n",
    "    \n",
    "stops=stopwords.words('english')+['year','would','whole','work','wonder','valu','ha','doe','wa','yet','without','yes','your']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vec = CountVectorizer(stop_words=stops,min_df=10,\n",
    "tokenizer=nltk.word_tokenize,max_features = 500, preprocessor=my_text_preprocessor)     \n",
    "review_counts = review_vec.fit_transform(review_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=review_vec.vocabulary_\n",
    "sorted(d.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_counts.shape)\n",
    "\n",
    "review_counts[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "review_tfidf = tfidf_transformer.fit_transform(review_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same dimensions, now with tf-idf values instead of raw frequency counts\n",
    "\n",
    "print(review_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "df_TF = pd.DataFrame(review_tfidf[:n].T.todense(), index=review_vec.get_feature_names(), columns=[str(\"TF-IDF:\"+str(i)) for i in range(n)])\n",
    "df_TF = df_TF.sort_values( df_TF.columns.values.tolist(),ascending=False)\n",
    "print(df_TF.shape)\n",
    "print (df_TF.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tfidf_array=review_tfidf.toarray()\n",
    "review_count_array=review_counts.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array='review_tfidf_array'\n",
    "kmeans= KMeans()\n",
    "truncatedsvd= TruncatedSVD()\n",
    "pipeline = make_pipeline(truncatedsvd,kmeans)\n",
    "param_grid={\"truncatedsvd__n_components\":[20,10,5,4,3,2],\"kmeans__n_clusters\":[5,6,3]},\n",
    "pip_search=GridSearchCV(pipeline,cv=5,\n",
    "                    refit=True,\n",
    "                    error_score='raise',\n",
    "                    param_grid=param_grid,n_jobs=8)\n",
    "# Fit the pipeline to articles\n",
    "pip_search.fit(input_array)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % pip_search.best_score_)\n",
    "print(pip_search.best_params_)\n",
    "labels = pip_search.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame aligning labels and titles: df\n",
    "df_classes = pd.DataFrame({'label': labels, 'review': review_tfidf})\n",
    "\n",
    "# Display df sorted by cluster label\n",
    "print(df_classes.sort_values('label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised classification by applying multible models then choose the one with the best result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Classification: \n",
    "Using Stars As LABEL: star>=3  ('good')  star<3 ('bad') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=(df_coffee_reviews['stars'] >=3.0)\n",
    "df_coffee_reviews['Cat_review']=np.where(m,'good','bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X=review_counts\n",
    "y=df_coffee_reviews['Cat_review']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X,y,test_size = 0.20, random_state = 2)\n",
    "sample_weight=compute_sample_weight(\"balanced\", y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Multimoda Naive Bayes classifier\n",
    "classifyer={\"decisionTreeclassifier\":DecisionTreeClassifier(),\"logisticregression\":LogisticRegression(max_iter=300),\n",
    "\"multinomialNB\":MultinomialNB(),'RandomForestClassifier':RandomForestClassifier(n_estimators=300)\n",
    ",'GradientBoostingClassifier':GradientBoostingClassifier(n_estimators=300)}\n",
    "for clf,model in classifyer.items():\n",
    "    clf = model.fit(X_train, y_train,sample_weight =sample_weight )\n",
    "    # Predicting the Test set results, find accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('results of {}={}'.format(clf,sklearn.metrics.accuracy_score(y_test, y_pred)))\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1\n",
    "adaboostclassifier=AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),n_estimators=300, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(adaboostclassifier, X, y, cv=5,n_jobs=-1)\n",
    "scores.mean()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=adaboostclassifier.fit(X_train, y_train,sample_weight =sample_weight)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('results of {}={}'.format(clf,sklearn.metrics.accuracy_score(y_test, y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the datafram as csv file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coffee_reviews.to_csv('coffee_review.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18c4b5af188fc8eff7c5790f9476cd665e7bfc3c428d80b914043c0e832408fd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('deep_learning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
